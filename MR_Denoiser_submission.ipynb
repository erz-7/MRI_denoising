{"cells":[{"cell_type":"markdown","metadata":{"id":"rV4a9SKm8pTR"},"source":["# Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1710084179557,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"Um7drBc96UCT","outputId":"6d62abf6-c747-4c58-fd9c-6183033ddb84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Apr  1 13:54:52 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA GeForce RTX 3080      WDDM  |   00000000:01:00.0  On |                  N/A |\n","| 35%   49C    P8             31W /  350W |    2305MiB /  12288MiB |     36%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A      1224    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n","|    0   N/A  N/A      1312    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n","|    0   N/A  N/A      2280    C+G   ...Files (x86)\\Surfshark\\Surfshark.exe      N/A      |\n","|    0   N/A  N/A      6392    C+G   ...41.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n","|    0   N/A  N/A      7496    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n","|    0   N/A  N/A      8372    C+G   C:\\Windows\\explorer.exe                     N/A      |\n","|    0   N/A  N/A      8876    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n","|    0   N/A  N/A     10204    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n","|    0   N/A  N/A     11880    C+G   ...on\\123.0.2420.65\\msedgewebview2.exe      N/A      |\n","|    0   N/A  N/A     12976    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n","|    0   N/A  N/A     13916    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n","|    0   N/A  N/A     15152    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n","|    0   N/A  N/A     15464    C+G   ...app-2.3.78\\Signal-x64\\SignalRgb.exe      N/A      |\n","|    0   N/A  N/A     18596    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n","|    0   N/A  N/A     22532    C+G   ...__8wekyb3d8bbwe\\Notepad\\Notepad.exe      N/A      |\n","|    0   N/A  N/A     22944    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n","|    0   N/A  N/A     29676    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n","|    0   N/A  N/A     30760    C+G   ...wekyb3d8bbwe\\XboxGameBarWidgets.exe      N/A      |\n","|    0   N/A  N/A     34520    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n","|    0   N/A  N/A     38128    C+G   ...treamer\\VirtualDesktop.Streamer.exe      N/A      |\n","|    0   N/A  N/A     53276    C+G   ...am Files (x86)\\SimHub\\SimHubWPF.exe      N/A      |\n","|    0   N/A  N/A     59880    C+G   ...r\\AppData\\Roaming\\Zoom\\bin\\Zoom.exe      N/A      |\n","|    0   N/A  N/A     64444    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n","|    0   N/A  N/A     65380    C+G   ...miker\\Downloads\\Content Manager.exe      N/A      |\n","|    0   N/A  N/A     66304    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n","|    0   N/A  N/A     68044    C+G   ...42.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n","|    0   N/A  N/A     77048    C+G   ....0_x64__8wekyb3d8bbwe\\PhotosApp.exe      N/A      |\n","|    0   N/A  N/A     80060      C   ...rograms\\Python\\Python311\\python.exe      N/A      |\n","+-----------------------------------------------------------------------------------------+\n","Python 3.11.7\n"]}],"source":["!nvidia-smi\n","!python --version"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10957,"status":"ok","timestamp":1710084190512,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"NT3W3eBz7a0r"},"outputs":[],"source":["#Deep learning\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torchmetrics.image import StructuralSimilarityIndexMeasure\n","\n","#Data Science\n","import pandas as pd\n","from scipy.stats import ttest_rel, gmean, ttest_1samp\n","\n","#visualization packages\n","import matplotlib.pyplot as plt # for plotting\n","\n","#util\n","import os\n","from prettytable import PrettyTable\n","import tqdm\n","from tkinter import filedialog\n","import tkinter as tk\n","import numpy as np # for transformation\n","\n","#Image manipulation\n","import skimage\n","from skimage.restoration import denoise_nl_means, estimate_sigma"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1710084246534,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"zwWeqF8n7UIq","outputId":"aa3b3fcf-5873-4a8f-e96e-481a7d514b91"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["#set the device to cuda:0\n","if torch.cuda.is_available():\n","  device = \"cuda:0\"\n","else:\n","  device = \"cpu\"\n","\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"X42Nr0lt80TK"},"source":["# Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710084308010,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"fdtaWPWweVAr"},"outputs":[],"source":["#create the dataset class\n","#Load In the Dataset\n","class MRI_Dataset(Dataset):\n","\n","  def __init__(self, data_path, flip=True, flip_prob=0.1, diagnostics=False):\n","    \"\"\"\n","        Args:\n","            data_path (string): Directory with the training data. The data will already be normalized\n","    \"\"\"\n","    #get list of data file names\n","    files = os.listdir(data_path)\n","    self.data_path = data_path\n","    self.real_files = [x for x in files if 'data_normalized' in x]\n","    if diagnostics == True:\n","      print('there are this many files in the list of data ', len(self.real_files))\n","\n","    self.slice_list = []\n","    loaded_tensors = None\n","    torch.cuda.empty_cache()\n","\n","    #define the l-r flip transform for data augmentation\n","    if flip == True:\n","      transform = transforms.Compose([\n","      transforms.RandomHorizontalFlip(p=flip_prob)])\n","    else:\n","      transform = transforms.Compose([\n","      transforms.RandomHorizontalFlip(p=0.0)])\n","\n","    #take that list and expand it based on each \"real_file\" N size. normalized_data_0.pt -> normalized_data_0_1, normalized_data_0_2...\n","    if diagnostics == True:\n","      for file in tqdm.tqdm(self.real_files):\n","\n","        #load in a single file (takes 15 seconds per file)\n","        loaded_tensors = torch.load(data_path +file) #loaded tensors will be N X 256 X 256\n","        N, _, _ = loaded_tensors.size()\n","\n","        #divide up the tensor between slices and append each one to the master list\n","        for i in range(N):\n","          #self.slice_list.append(loaded_tensors[N-1,:,:]) #this is just repeating the last slice N times\n","          self.slice_list.append(transform(loaded_tensors[i,:,:]))\n","\n","    else:\n","      #same as above just without tqdm to declutter the output\n","      for file in (self.real_files):\n","\n","        loaded_tensors = torch.load(data_path +file)\n","        N, _, _ = loaded_tensors.size()\n","\n","        for i in range(N):\n","\n","          self.slice_list.append(transform(loaded_tensors[i,:,:]))\n","\n","      #insert this break if you want to only load a single file in just a few secs instead of 7 minutes for the whole thing\n","      #break\n","\n","  #this is a required function that tells you how many data points you have in the dataset\n","  def __len__(self):\n","      return len(self.slice_list)\n","\n","  #this is a required function that allows you to obtain a single data point according to its index\n","  def __getitem__(self, idx):\n","\n","    #we have self.slice_list containing: e.g. data_normalized_1_2961.pt\n","    MRI_image = self.slice_list[idx]\n","\n","    return MRI_image"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93254,"status":"ok","timestamp":1710084472389,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"IyxzG00ccNMC","outputId":"a724dd10-dc6f-4d3f-81e8-9e75cf20b276"},"outputs":[{"name":"stdout","output_type":"stream","text":["there are this many files in the list of data  1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n"]}],"source":["#try the dataset creator\n","torch.cuda.empty_cache()\n","\n","MRI_dataset = MRI_Dataset(data_path=\"C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\testdir\\\\\", diagnostics=True) #Michael's instance - test mode\n","MRI_dataloader = DataLoader(MRI_dataset, batch_size=76, shuffle=True, drop_last=False) #TEMPORARILY SET DROP_LAST TO FALSE, CHANGE LATER"]},{"cell_type":"markdown","metadata":{"id":"IF7D5n1w6Op5"},"source":["# Noise generation and utilities"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":154,"status":"ok","timestamp":1710086321602,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"rybkU3zuJDTx"},"outputs":[],"source":["def gaussian_noise_gen(input_tensor, mode=\"train\", fixed_sigma=5):\n","    \"\"\"\n","    This function adds random gaussian noise to an input image tensor and returns a new tensor.\n","\n","    Parameters\n","    ----------\n","    input_tensor : torch.Tensor\n","        A tensor representing an image.\n","    mode : str\n","        A string that determines whether the noise sigma is randomly generated or fixed.\n","    fixed_sigma : int\n","        An integer that determines the fixed noise sigma to use in percent if mode is set to \"fixed\".\n","\n","    Returns\n","    -------\n","    tensor_to_return : torch.Tensor\n","        A tensor representing the noised image.\n","\n","    Examples\n","    --------\n","    >>> input_tensor = torch.rand(1, 256, 256) # a random grayscale image\n","    >>> noised_tensor = noise_gen(input_tensor) # add noise to the image\n","    >>> noised_tensor.shape\n","    torch.Size([1, 256, 256])\n","    \"\"\"\n","    global device\n","    \n","    # Convert the input tensor to a numpy array and handle any NaN values\n","    try:\n","        input_tensor = input_tensor.cpu().numpy()\n","        input_tensor = np.nan_to_num(input_tensor)\n","    except:\n","        input_tensor = input_tensor.cpu().detach().numpy()\n","        input_tensor = np.nan_to_num(input_tensor)\n","\n","    # Randomly generate the noise sigma - 1% to 20% of the max value of the image as per Manjon et al, 2018\n","    if mode == \"train\":\n","        noise_thresholds = [0.01, 0.03, 0.05, 0.07, 0.09]\n","    elif mode == \"fixed\":\n","        if fixed_sigma == 5:\n","            noise_thresholds = [0.05]\n","        elif fixed_sigma == 1:\n","            noise_thresholds = [0.01]\n","        elif fixed_sigma == 3:\n","            noise_thresholds = [0.03]\n","        elif fixed_sigma == 7:\n","            noise_thresholds = [0.07]\n","        elif fixed_sigma == 9:\n","            noise_thresholds = [0.09]\n","    stddev = np.random.choice(noise_thresholds, size=None, replace=True) * np.max(input_tensor) #max should be 1 so this is theoretically useless\n","\n","    # Generate the noise and add it to the image\n","    noise = np.random.normal(0, stddev, input_tensor.shape).astype(np.float32)\n","    noised_img = (input_tensor + noise).astype(np.float32)\n","    del input_tensor\n","    \n","    return torch.tensor(noised_img).to(device).float(), torch.tensor(noise).to(device).float()\n","\n","\n","def rician_noise_gen(input_tensor_real, input_tensor_imag):\n","    \"\"\"\n","    This function adds random rician noise to an input image tensor and returns a new tensor.\n","\n","    Parameters\n","    ----------\n","    input_tensor : torch.Tensor\n","        A tensor representing an image.\n","    input_tensor_imag : torch.Tensor\n","        A tensor representing the imaginary part of the image.\n","\n","    Returns\n","    -------\n","    tensor_to_return : torch.Tensor\n","        A tensor representing the noised image.\n","\n","    Examples\n","    --------\n","    >>> input_tensor = torch.rand(1, 256, 256) # a random grayscale image\n","    >>> noised_tensor = rician_noise_gen(input_tensor) # add noise to the image\n","    >>> noised_tensor.shape\n","    torch.Size([1, 256, 256])\n","    \"\"\"\n","    global device\n","\n","    try:\n","        tensor_np = input_tensor_real.cpu().numpy()\n","        tensor_np = np.nan_to_num(tensor_np)\n","        tensor_i_np = input_tensor_imag.cpu().numpy()\n","        tensor_i_np = np.nan_to_num(tensor_i_np)\n","    except:\n","        tensor_np = input_tensor_real.cpu().detach().numpy()\n","        tensor_np = np.nan_to_num(tensor_np)\n","        tensor_i_np = input_tensor_imag.cpu().detach().numpy()\n","        tensor_i_np = np.nan_to_num(tensor_i_np)\n","\n","    N = tensor_np.size  # how many samples\n","    \n","    # Randomly generate the noise sigma - 1% to 9% of the max value of the image\n","    noise_thresholds = [0.01, 0.03, 0.05, 0.07, 0.09]\n","    s = np.random.choice(noise_thresholds, size=None, replace=True) * np.max(tensor_np) #max should be 1 so this is theoretically useless\n","\n","    noise_real = np.random.normal(0, s, tensor_np.shape)\n","    noise_imag = np.random.normal(0, s, tensor_np.shape)\n","\n","    # Create a complex noise signal\n","    noise_complex = noise_real + 1j*noise_imag\n","\n","    # Add the noise to the original image (assuming the image is real-valued)\n","    noised_img = np.abs(tensor_np + noise_complex)\n","    del tensor_np, noise_real, noise_imag, noise_complex\n","\n","    return (torch.tensor(noised_img).to(device)).float()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def tkinter_gui(flavour_text):\n","    \"\"\"\n","    This function creates a Tkinter window for browsing directories and returns the selected directory path.\n","\n","    Parameters\n","    ----------\n","    flavour_text : str\n","        A string to display in the Tkinter window.\n","\n","    Returns\n","    -------\n","    selected_directory : str\n","        The selected directory path.\n","\n","    Examples\n","    --------\n","    >>> selected_directory = tkinter_gui(\"Select a directory\")\n","    \"\"\"\n","    \n","    def browse_directory():\n","        directory_path = filedialog.askdirectory()\n","        if directory_path:\n","            nonlocal selected_directory\n","            selected_directory = directory_path\n","            root.destroy()  # Close the Tkinter window\n","\n","    # Create the main window\n","    root = tk.Tk()\n","    root.title(\"Directory Browser\")\n","\n","    # Create a label and button to display selected directory and browse\n","    directory_label = tk.Label(root, text=flavour_text, padx=10, pady=10)\n","    directory_label.pack()\n","    browse_button = tk.Button(root, text=\"Browse\", command=browse_directory)\n","    browse_button.pack()\n","\n","    # Run the application\n","    selected_directory = None  # Initialize selected_directory variable\n","    root.mainloop()\n","    if selected_directory:\n","        return selected_directory   \n","    else:\n","        raise ValueError(\"No directory selected\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1WeZ-KP25KJkyvW1yO_HNN4eEcvqvQOcA"},"executionInfo":{"elapsed":72759,"status":"ok","timestamp":1710086405088,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":240},"id":"cJKnDtJ6jtVn","outputId":"aa9dc74b-dafc-4048-c8fe-9c342f7ef251"},"outputs":[],"source":["noise_dec = input(\"Would you like to add Gaussian noise or Rician noise as a test? (g/r/n): \")\n","if noise_dec.lower() in [\"g\", \"r\"]:\n","  for i in range(len(MRI_dataloader)):\n","    sample = next(iter(MRI_dataloader))  \n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n","\n","    ax1.imshow(sample[75].cpu().data.numpy(), cmap = \"gray\")\n","    ax1.set_title(\"Original image\")\n","\n","    single_image_noised = gaussian_noise_gen(sample)[0]\n","    ax2.imshow(single_image_noised[75].cpu().data.numpy(), cmap = \"gray\")\n","    ax2.set_title(\"Noisy image\")\n","\n","    plt.show()\n","\n","    print(\"PSNR ratio of original image: inf\") #should be inf, higher PSNR is better and we haven't changed anything here\n","    print(\"PSNR ratio of noisy image: \", skimage.metrics.peak_signal_noise_ratio(sample[75].cpu().data.numpy(), single_image_noised[75].cpu().data.numpy())) #should be low due to additive noise\n","    if i > 5:\n","      break"]},{"cell_type":"markdown","metadata":{"id":"f8h4FKmECmOY"},"source":["# Network"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"elapsed":120,"status":"ok","timestamp":1709829773407,"user":{"displayName":"Mike M","userId":"12898780954477316855"},"user_tz":300},"id":"JYH0xaMroDV_","outputId":"63e8cbec-d443-4811-bb9a-5f67210d2929"},"outputs":[],"source":["#block architectures\n","class downsample_block_new(nn.Module):\n","  def __init__(self, dims, kernel_size = 3, stride=2, num_channels_in=1, num_channels_out=1):\n","        super(downsample_block_new, self).__init__()\n","\n","        self.lrelu = nn.LeakyReLU()\n","        self.dims = dims\n","\n","\n","        self.conv_down1 = nn.Conv2d(num_channels_in, num_channels_out, stride=stride, kernel_size = kernel_size, padding=kernel_size-3, padding_mode='reflect')\n","        self.bn_down1 = nn.BatchNorm2d(num_channels_out)\n","        self.conv_down2 = nn.Conv2d(num_channels_out, num_channels_out, kernel_size = kernel_size, padding = \"same\")\n","        self.bn_down2 = nn.BatchNorm2d(num_channels_out)\n","\n","\n","  def forward(self, x):\n","\n","        x = self.conv_down1(x)\n","        x = self.lrelu(self.bn_down1(x))\n","        x = self.conv_down2(x)\n","        x = self.lrelu(self.bn_down2(x))\n","\n","        return x\n","  \n","\n","\n","class downsample_block_new_2(nn.Module):\n","  def __init__(self, dims, kernel_size = 3, stride=2, num_channels_in=1, num_channels_out=1):\n","        super(downsample_block_new_2, self).__init__()\n","\n","        self.lrelu = nn.LeakyReLU()\n","        self.dims = dims\n","\n","\n","        self.conv_down1 = nn.Conv2d(num_channels_in, num_channels_out, stride=stride, kernel_size = kernel_size, padding=kernel_size-2, padding_mode='reflect')\n","        self.bn_down1 = nn.BatchNorm2d(num_channels_out)\n","        self.conv_down2 = nn.Conv2d(num_channels_out, num_channels_out, kernel_size = kernel_size, padding = \"same\")\n","        self.bn_down2 = nn.BatchNorm2d(num_channels_out)\n","\n","\n","  def forward(self, x):\n","\n","        x = self.conv_down1(x)\n","        x = self.lrelu(self.bn_down1(x))\n","        x = self.conv_down2(x)\n","        x = self.lrelu(self.bn_down2(x))\n","\n","        return x\n","\n","\n","class upsample_block_new(nn.Module):\n","  def __init__(self, dims, kernel_size = 5, padding_ = \"same\", num_channels_in=1, num_channels_out=1):\n","        super(upsample_block_new, self).__init__()\n","\n","        self.lrelu = nn.LeakyReLU()\n","        self.dims = dims\n","\n","        self.bn1 = nn.BatchNorm2d(num_channels_in)\n","        self.conv_up1 = nn.Conv2d(num_channels_in, num_channels_out, kernel_size = kernel_size, padding = padding_)\n","        self.bn_up1 = nn.BatchNorm2d(num_channels_out)\n","        self.lrelu = nn.LeakyReLU()\n","        self.conv_up2 = nn.Conv2d(num_channels_out, num_channels_out, kernel_size = kernel_size, padding = padding_)\n","        self.bn_up2 = nn.BatchNorm2d(num_channels_out)\n","\n","  def forward(self, x):\n","\n","        x = self.bn1(x)\n","        x = self.conv_up1(x)\n","        x = self.lrelu(self.bn_up1(x))\n","        x = self.conv_up2(x)\n","        x = self.bn_up2(x)\n","        x = nn.functional.interpolate(x, size = self.dims, mode='bilinear', align_corners=True)\n","\n","        return x\n","\n","\n","class midblock_new(nn.Module):\n","  def __init__(self, kernel_size = 3, padding_ = \"same\", num_channels=1):\n","        super(midblock_new, self).__init__()\n","\n","        self.midconv = nn.Conv2d(num_channels, num_channels, kernel_size = kernel_size, padding = padding_)\n","        self.bn_mid = nn.BatchNorm2d(num_channels)\n","\n","  def forward(self, x):\n","\n","        x = self.midconv(x)\n","        x = self.bn_mid(x)\n","\n","        return x\n","  \n","\n","class skipblock_new(nn.Module):\n","  def __init__(self, kernel_size = 3, padding_ = \"same\", num_channels_in=1, num_channels_out=1):\n","        super(skipblock_new, self).__init__()\n","\n","        self.lrelu = nn.LeakyReLU()\n","\n","        self.conv_down1 = nn.Conv2d(num_channels_in, num_channels_out, kernel_size = kernel_size, padding = padding_)\n","        self.bn_down1 = nn.BatchNorm2d(num_channels_out)\n","\n","  def forward(self, x):\n","\n","        x = self.conv_down1(x)\n","        x = self.lrelu(self.bn_down1(x))\n","\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#network architecture\n","class DenoiseNET_structure3(nn.Module):\n","    def __init__(self):\n","        super(DenoiseNET_structure3, self).__init__()\n","\n","        self.downblock1 = downsample_block_new(dims = (128,128), kernel_size=5, num_channels_in=1, num_channels_out=8)\n","        self.skipblock1 = skipblock_new(num_channels_in = 8, num_channels_out = 4)\n","\n","        self.downblock2 = downsample_block_new(dims = (64,64), kernel_size=5, num_channels_in=8, num_channels_out=16)\n","        self.skipblock2 = skipblock_new(num_channels_in = 16, num_channels_out=4)\n","\n","        self.downblock3 = downsample_block_new_2(dims = (32,32), num_channels_in=16, num_channels_out=32)\n","        self.skipblock3 = skipblock_new(num_channels_in = 32, num_channels_out=4)\n","\n","        self.downblock4 = downsample_block_new_2(dims = (16,16), num_channels_in=32, num_channels_out=64)\n","        self.skipblock4 = skipblock_new(num_channels_in = 64, num_channels_out=4)\n","\n","        self.downblock5 = downsample_block_new_2(dims = (8,8), num_channels_in=64, num_channels_out=64)\n","        self.skipblock5 = skipblock_new(num_channels_in = 64, num_channels_out=4)\n","\n","        self.connect = midblock_new(num_channels=64)\n","\n","        self.upblock0 = upsample_block_new(dims = (16,16), num_channels_in=68, num_channels_out=64)\n","        self.upblock1 = upsample_block_new(dims = (32,32), num_channels_in=68, num_channels_out=32)\n","        self.upblock2 = upsample_block_new(dims = (64,64), num_channels_in=36, num_channels_out=16)\n","        self.upblock3 = upsample_block_new(dims = (128,128), kernel_size=5, num_channels_in=20, num_channels_out=8)\n","        self.upblock4 = upsample_block_new(dims = (256,256), kernel_size=5, num_channels_in=12, num_channels_out=1)\n","\n","    def forward(self, x):\n","        \n","        x = self.downblock1(x)\n","        skip_1 = self.skipblock1(x)\n","\n","        x = self.downblock2(x)\n","        skip_2 = self.skipblock2(x)\n","\n","        x = self.downblock3(x)\n","        skip_3 = self.skipblock3(x)\n","\n","        x = self.downblock4(x)\n","        skip_4 = self.skipblock4(x)\n","\n","        x = self.downblock5(x)\n","        skip_5 = self.skipblock5(x)\n","\n","        x = self.connect(x)\n","\n","        x = torch.cat([x, skip_5], dim=1)\n","        x = self.upblock0(x)\n","\n","        x = torch.cat([x, skip_4], dim=1)\n","        x = self.upblock1(x)\n","\n","        x = torch.cat([x, skip_3], dim=1)\n","        x = self.upblock2(x)\n","\n","        x = torch.cat([x, skip_2], dim=1)\n","        x = self.upblock3(x)\n","        \n","        x = torch.cat([x, skip_1], dim=1)\n","        x = self.upblock4(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"oIRD6gaew4en"},"outputs":[],"source":["#test the input and output shapes\n","torch.cuda.empty_cache()\n","input_tensor = torch.rand(4,1,256,256).to(device)\n","network = DenoiseNET_structure3().to(device)\n","output_tensor = network(input_tensor)\n","del network"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709667538057,"user":{"displayName":"Rick Sugden","userId":"15823990273823469204"},"user_tz":300},"id":"utsddwee9hHr","outputId":"bc3ac5e0-5d51-4d0a-fdb0-d7062b709de7"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------------------+------------+\n","|           Modules            | Parameters |\n","+------------------------------+------------+\n","| downblock1.conv_down1.weight |    200     |\n","|  downblock1.conv_down1.bias  |     8      |\n","|  downblock1.bn_down1.weight  |     8      |\n","|   downblock1.bn_down1.bias   |     8      |\n","| downblock1.conv_down2.weight |    1600    |\n","|  downblock1.conv_down2.bias  |     8      |\n","|  downblock1.bn_down2.weight  |     8      |\n","|   downblock1.bn_down2.bias   |     8      |\n","| skipblock1.conv_down1.weight |    288     |\n","|  skipblock1.conv_down1.bias  |     4      |\n","|  skipblock1.bn_down1.weight  |     4      |\n","|   skipblock1.bn_down1.bias   |     4      |\n","| downblock2.conv_down1.weight |    3200    |\n","|  downblock2.conv_down1.bias  |     16     |\n","|  downblock2.bn_down1.weight  |     16     |\n","|   downblock2.bn_down1.bias   |     16     |\n","| downblock2.conv_down2.weight |    6400    |\n","|  downblock2.conv_down2.bias  |     16     |\n","|  downblock2.bn_down2.weight  |     16     |\n","|   downblock2.bn_down2.bias   |     16     |\n","| skipblock2.conv_down1.weight |    576     |\n","|  skipblock2.conv_down1.bias  |     4      |\n","|  skipblock2.bn_down1.weight  |     4      |\n","|   skipblock2.bn_down1.bias   |     4      |\n","| downblock3.conv_down1.weight |    4608    |\n","|  downblock3.conv_down1.bias  |     32     |\n","|  downblock3.bn_down1.weight  |     32     |\n","|   downblock3.bn_down1.bias   |     32     |\n","| downblock3.conv_down2.weight |    9216    |\n","|  downblock3.conv_down2.bias  |     32     |\n","|  downblock3.bn_down2.weight  |     32     |\n","|   downblock3.bn_down2.bias   |     32     |\n","| skipblock3.conv_down1.weight |    1152    |\n","|  skipblock3.conv_down1.bias  |     4      |\n","|  skipblock3.bn_down1.weight  |     4      |\n","|   skipblock3.bn_down1.bias   |     4      |\n","| downblock4.conv_down1.weight |   18432    |\n","|  downblock4.conv_down1.bias  |     64     |\n","|  downblock4.bn_down1.weight  |     64     |\n","|   downblock4.bn_down1.bias   |     64     |\n","| downblock4.conv_down2.weight |   36864    |\n","|  downblock4.conv_down2.bias  |     64     |\n","|  downblock4.bn_down2.weight  |     64     |\n","|   downblock4.bn_down2.bias   |     64     |\n","| skipblock4.conv_down1.weight |    2304    |\n","|  skipblock4.conv_down1.bias  |     4      |\n","|  skipblock4.bn_down1.weight  |     4      |\n","|   skipblock4.bn_down1.bias   |     4      |\n","| downblock5.conv_down1.weight |   36864    |\n","|  downblock5.conv_down1.bias  |     64     |\n","|  downblock5.bn_down1.weight  |     64     |\n","|   downblock5.bn_down1.bias   |     64     |\n","| downblock5.conv_down2.weight |   36864    |\n","|  downblock5.conv_down2.bias  |     64     |\n","|  downblock5.bn_down2.weight  |     64     |\n","|   downblock5.bn_down2.bias   |     64     |\n","| skipblock5.conv_down1.weight |    2304    |\n","|  skipblock5.conv_down1.bias  |     4      |\n","|  skipblock5.bn_down1.weight  |     4      |\n","|   skipblock5.bn_down1.bias   |     4      |\n","|    connect.midconv.weight    |   36864    |\n","|     connect.midconv.bias     |     64     |\n","|    connect.bn_mid.weight     |     64     |\n","|     connect.bn_mid.bias      |     64     |\n","|     upblock0.bn1.weight      |     68     |\n","|      upblock0.bn1.bias       |     68     |\n","|   upblock0.conv_up1.weight   |   108800   |\n","|    upblock0.conv_up1.bias    |     64     |\n","|    upblock0.bn_up1.weight    |     64     |\n","|     upblock0.bn_up1.bias     |     64     |\n","|   upblock0.conv_up2.weight   |   102400   |\n","|    upblock0.conv_up2.bias    |     64     |\n","|    upblock0.bn_up2.weight    |     64     |\n","|     upblock0.bn_up2.bias     |     64     |\n","|     upblock1.bn1.weight      |     68     |\n","|      upblock1.bn1.bias       |     68     |\n","|   upblock1.conv_up1.weight   |   54400    |\n","|    upblock1.conv_up1.bias    |     32     |\n","|    upblock1.bn_up1.weight    |     32     |\n","|     upblock1.bn_up1.bias     |     32     |\n","|   upblock1.conv_up2.weight   |   25600    |\n","|    upblock1.conv_up2.bias    |     32     |\n","|    upblock1.bn_up2.weight    |     32     |\n","|     upblock1.bn_up2.bias     |     32     |\n","|     upblock2.bn1.weight      |     36     |\n","|      upblock2.bn1.bias       |     36     |\n","|   upblock2.conv_up1.weight   |   14400    |\n","|    upblock2.conv_up1.bias    |     16     |\n","|    upblock2.bn_up1.weight    |     16     |\n","|     upblock2.bn_up1.bias     |     16     |\n","|   upblock2.conv_up2.weight   |    6400    |\n","|    upblock2.conv_up2.bias    |     16     |\n","|    upblock2.bn_up2.weight    |     16     |\n","|     upblock2.bn_up2.bias     |     16     |\n","|     upblock3.bn1.weight      |     20     |\n","|      upblock3.bn1.bias       |     20     |\n","|   upblock3.conv_up1.weight   |    4000    |\n","|    upblock3.conv_up1.bias    |     8      |\n","|    upblock3.bn_up1.weight    |     8      |\n","|     upblock3.bn_up1.bias     |     8      |\n","|   upblock3.conv_up2.weight   |    1600    |\n","|    upblock3.conv_up2.bias    |     8      |\n","|    upblock3.bn_up2.weight    |     8      |\n","|     upblock3.bn_up2.bias     |     8      |\n","|     upblock4.bn1.weight      |     12     |\n","|      upblock4.bn1.bias       |     12     |\n","|   upblock4.conv_up1.weight   |    300     |\n","|    upblock4.conv_up1.bias    |     1      |\n","|    upblock4.bn_up1.weight    |     1      |\n","|     upblock4.bn_up1.bias     |     1      |\n","|   upblock4.conv_up2.weight   |     25     |\n","|    upblock4.conv_up2.bias    |     1      |\n","|    upblock4.bn_up2.weight    |     1      |\n","|     upblock4.bn_up2.bias     |     1      |\n","+------------------------------+------------+\n","Total Trainable Params: 518151\n"]}],"source":["def count_parameters(model):\n","    \"\"\"\n","    This function counts the number of trainable parameters in a PyTorch model and prints the results in a table format using the PrettyTable package.\n","\n","    Parameters\n","    ----------\n","    model : torch.nn.Module\n","        A PyTorch model.\n","\n","    Returns\n","    -------\n","    total_params : int\n","        The total number of trainable parameters in the model.\n","\n","    Examples\n","    --------\n","    >>> model = UNet().to(device)\n","    >>> count_parameters(model)\n","    \"\"\"\n","\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad:\n","            continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params += params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","\n","model = DenoiseNET_structure3().to(device)\n","count_parameters(model)\n","del model"]},{"cell_type":"markdown","metadata":{"id":"R38-GklpCQHG"},"source":["# Training and validation methods"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"hO1McNxfFlRk"},"outputs":[],"source":["def train(model, epochs=30, batch_size=8, learning_rate=0.0001, training_loss_tracker=[], val_loss_tracker=[], anomaly_detection=False, patience=5, device=device):\n","    '''\n","    This function trains and validates a model using the Adam optimizer and Mean Squared Error loss function. Displays loss at each step. It also uses a learning rate scheduler if lr dercay is needed.\n","\n","    Parameters\n","    ----------\n","    model : torch.nn.Module\n","        The neural network model to be trained.\n","    epochs : int\n","        The number of epochs to train the model.\n","    batch_size : int\n","        The number of samples to be used in each batch.\n","    learning_rate : float\n","        The learning rate to be used by the optimizer.\n","    training_loss_tracker : list\n","        A list to store the training loss values.\n","    val_loss_tracker : list\n","        A list to store the validation loss values.\n","    anomaly_detection : bool\n","        A flag to indicate whether to use PyTorch's anomaly detection feature. Also prints out diagnostic infomation across each step (verbose mode).\n","    patience : int\n","        The number of epochs to wait before early stopping.\n","    device\n","        The device to be used for training (e.g. 'cuda:0' or 'cpu').\n","\n","    Returns\n","    -------\n","    model : torch.nn.Module\n","        The trained model.\n","    training_loss_tracker : list\n","        A list of the training loss values.\n","    val_loss_tracker : list\n","        A list of the validation loss values.\n","\n","    Examples\n","    --------\n","    >>> model = DenoiseNET().to(device)\n","    >>> trained_model, training_loss_tracker, val_loss_tracker = train(model, epochs=30, batch_size=8, learning_rate=0.00001, training_loss_tracker=[], val_loss_tracker=[], anomaly_detection=False, device=device)\n","  \n","    '''\n","    assert epochs > len(training_loss_tracker), 'Loss tracker is already equal to or greater than epochs'\n","\n","    #define loss function and optimizer\n","    criterion1 = torch.nn.MSELoss()\n","    ssim_loss = StructuralSimilarityIndexMeasure(data_range=(-1.0, 1.0)).to(device)\n","    optimizer = optim.Adam(model.parameters(), betas = (0.9, 0.98), eps = 1.0e-9, lr=learning_rate)\n","\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.60)\n","    start_decay_epoch = 3\n","\n","    ####start a timer####\n","    start = torch.cuda.Event(enable_timing=True)\n","    end = torch.cuda.Event(enable_timing=True)\n","    start.record()\n","\n","    #initialize early stopping variables\n","    current_epoch = len(training_loss_tracker)\n","    best_val_loss = float('inf')\n","    val_counter_term = 0\n","\n","    #here, we take Epoch in a deep learning sense (i.e. iteration of training over the whole dataset)\n","    for epoch in tqdm.tqdm(range(current_epoch, epochs)):\n","        model.train()\n","        print(\"Current learning rate: \", scheduler.get_last_lr())\n","\n","        if anomaly_detection == True:\n","          print('epoch ', epoch)\n","        running_loss = 0.0\n","        train_counter = 0\n","\n","        #early stopping check\n","        if val_counter_term >= patience:\n","          print(f'Early stopping after {epoch} epochs')\n","          break\n","\n","        for i in (range(5)): #change to whatever the length of the dataloader is - should be 5\n","          if anomaly_detection == True:\n","            print('loading in the dataset of partition ', i)\n","          dataset_partition, train_dataloader = None, None\n","          torch.cuda.empty_cache()\n","\n","          dataset_partition = MRI_Dataset(data_path='C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\partition_'+str(i)+'\\\\')\n","          #dataset_partition = MRI_Dataset(data_path='C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\test_partition\\\\')\n","          train_dataloader = DataLoader(dataset_partition, batch_size=batch_size, shuffle=True, drop_last=True)\n","          if anomaly_detection == True:\n","             print('now training batches')\n","\n","          for i, mri_image_batch in enumerate(train_dataloader, 0): #(train_dataloader, 0): ### MRI image on GPU\n","              # get the inputs; data is a list of [inputs, labels]\n","              mri_image_batch = mri_image_batch.unsqueeze(1).float()#.to(device)  # Insert a dimension at index 1\n","              mri_image_batch = torch.nan_to_num(mri_image_batch, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","              # check if input is invalid, handle any data abberations and raise exception if needed\n","              if np.all(mri_image_batch.cpu().data.numpy() == 0) is True or np.any(np.isnan(mri_image_batch.cpu().data.numpy())) is True:\n","                print(\"Zeros: \", np.all(mri_image_batch.cpu().data.numpy() == 0))\n","                print(\"NaNs: \", np.any(np.isnan(mri_image_batch.cpu().data.numpy())))\n","                raise Exception(\"Invalid input\")\n","              \n","              noised_img_train, noise_train = gaussian_noise_gen(mri_image_batch, mode=\"train\")\n","\n","              # forward pass\n","              outputs = model(noised_img_train).float()\n","\n","              #recovered image for loss calculation\n","              recovered_img_train = noised_img_train - outputs\n","\n","              #Apply L2 Regularization. Replace pow(2.0) with abs() for L1 regularization\n","              l2_lambda = 0.0001\n","              l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n","\n","              #forward pass + loss + backward + optimize\n","              #normal mode\n","              c1 = criterion1(noise_train, outputs)\n","              c2 = l2_lambda*l2_norm\n","              c3 = 1 - ssim_loss(mri_image_batch, recovered_img_train)\n","              loss = 10*c1 + c2 #+ 0.1*c3\n","              loss.backward()\n","              optimizer.step()\n","\n","              # zero the parameter gradients\n","              optimizer.zero_grad()\n","  \n","              running_loss += loss.item()\n","              train_counter += 1\n","          \n","          #compute loss for epoch\n","          avg_train_loss = running_loss/train_counter\n","          training_loss_tracker.append(avg_train_loss)\n","\n","          print('[epoch: %d, batch: %5d] average training loss: %.3f' % (epoch + 1, i + 1, avg_train_loss ))\n","\n","          # flush memory\n","          del dataset_partition, train_dataloader\n","          torch.cuda.empty_cache()\n","\n","\n","\n","        #validation step\n","        val_every = 1\n","        if epoch % val_every == 0:\n","          model.eval()\n","          \n","          #import the validation dataset\n","          validation_partition = MRI_Dataset(data_path='C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\val_partition\\\\')\n","          val_dataloader = DataLoader(validation_partition, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","          #training_loss_tracker.append(running_loss/counter)\n","          val_counter = 0\n","          current_val_loss = 0.0\n","          for i, val_batch in enumerate(val_dataloader):\n","            val_batch = val_batch.unsqueeze(1).float()\n","            #fix any NaNs or Infs\n","            val_batch = torch.nan_to_num(val_batch, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","            #add noise to the image\n","            noised_img_val, noise_val = gaussian_noise_gen(val_batch, mode=\"fixed\")\n","\n","            #forward pass + loss\n","            val_outputs = model(noised_img_val).float()\n","\n","            #recovered image for loss calculation\n","            recovered_img_val = noised_img_val - val_outputs\n","\n","            c1 = criterion1(noise_val, val_outputs)\n","            c3 = 1 - ssim_loss(val_batch, recovered_img_val)\n","            val_loss = 10*c1 + c2 #+ 0.1*c3\n","            current_val_loss += val_loss.item()\n","            val_counter += 1\n","\n","          #early stopping\n","          if current_val_loss < best_val_loss:\n","            best_val_loss = current_val_loss\n","            val_counter_term = 0\n","          else:\n","            val_counter_term += 1\n","          \n","          #compute psnr and rmse for epoch\n","          val_batch_np = val_batch.cpu().data.numpy()\n","          val_outputs_np = recovered_img_val.cpu().data.numpy()\n","          psnr = skimage.metrics.peak_signal_noise_ratio(val_batch_np, val_outputs_np)\n","          ssim_comp = ssim_loss(val_batch, recovered_img_val).tolist()\n","          rmse = np.sqrt(skimage.metrics.mean_squared_error(val_batch_np, val_outputs_np))\n","\n","          #compute VAL loss for epoch\n","          avg_val_loss = current_val_loss/val_counter\n","          val_loss_tracker.append(avg_val_loss)\n","\n","          #print statistics\n","          print('[epoch: %d, batch: %5d] average validation loss: %.3f' % (epoch + 1, i + 1, avg_val_loss ))\n","          print('PSNR: ', psnr)\n","          print('SSIM: ', ssim_comp)\n","          print('RMSE: ', rmse)\n","\n","          #create a sample image test for visualization\n","          fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n","\n","          ax1.imshow(val_batch_np[0][0], cmap = \"gray\")\n","          ax1.set_title(\"Original image at epoch %d\")\n","\n","          ax2.imshow(((gaussian_noise_gen(val_batch, mode=\"fixed\")[0]).cpu().data.numpy())[0][0], cmap = \"gray\")\n","          ax2.set_title(\"Sample noisy image at epoch %d\")\n","\n","          ax3.imshow(val_outputs_np[0][0], cmap = \"gray\")\n","          ax3.set_title(\"Denoised image at epoch %d\")\n","\n","          plt.show()\n","\n","          # flush memory  \n","          del validation_partition, val_dataloader, val_batch_np, val_outputs_np\n","          torch.cuda.empty_cache()\n","        \n","          #learning rate scheduler for decay\n","          if epoch >= start_decay_epoch:\n","            scheduler.step()\n","\n","    final_val_stat = [psnr, ssim_comp, rmse]\n","\n","    # whatever you are timing goes here\n","    end.record()\n","\n","    # Waits for everything to finish running\n","    torch.cuda.synchronize()\n","\n","    print('Finished Training Session')\n","    print('Time elapsed in miliseconds: ', start.elapsed_time(end))  # milliseconds\n","    print('The training loss at the end of this session is: ', loss.item())\n","\n","    return model, training_loss_tracker, val_loss_tracker, final_val_stat\n"]},{"cell_type":"markdown","metadata":{"id":"-IfJ7RJZCbbN"},"source":["# Main method"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ZE6QAA9qxeuA"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/30 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Current learning rate:  [0.0001]\n","[epoch: 1, batch:   234] average training loss: 4.406\n"]}],"source":["#clear the memory\n","try:\n","  del MRI_dataset, MRI_dataloader\n","except:\n","  pass\n","torch.cuda.empty_cache()\n","\n","dec_train = (input(\"Do you want to train the model? (y/n): \")).lower()\n","if dec_train == 'y':\n","\n","    #test the training loop - define the learning rates to try\n","    lrs_to_try = [0.0001]\n","    statistics = {}\n","    models = []\n","\n","    #make sure to clear the model and cache before training\n","    for lr in lrs_to_try:\n","        try:\n","            del model\n","        except:\n","            pass\n","        torch.cuda.empty_cache()\n","\n","        #initialize the model and train\n","        model = DenoiseNET_structure3().to(device)\n","        trained_model, training_loss, training_val, val_stats = train(model,batch_size=64, epochs=30, learning_rate=lr, training_loss_tracker=[], val_loss_tracker=[])\n","        \n","        #store the model and stats\n","        statistics[lr] = [trained_model, training_loss, training_val, val_stats]\n","        models.append(trained_model.to('cpu'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def saliency_generator(model, input_tensor):\n","    \"\"\"\n","    This function generates a saliency map for a given input image tensor.\n","\n","    Parameters\n","    ----------\n","    model : torch.nn.Module\n","        The neural network model to be used for generating the saliency map.\n","    input_tensor : torch.Tensor\n","        A tensor representing an image.\n","\n","    Returns\n","    -------\n","    saliency_map : np.array\n","        A numpy array representing the saliency map.\n","\n","    Examples\n","    --------\n","    >>> model = DenoiseNET().to(device)\n","    >>> input_tensor = torch.rand(1, 1, 256, 256) # a random grayscale image\n","    >>> saliency_map = saliency_generator(model, input_tensor) # generate the saliency map\n","    >>> saliency_map.shape\n","    (256, 256)\n","    \"\"\"\n","    # Assuming you're adding noise or generating a tensor\n","    model.eval()\n","    model = model.to(device)\n","\n","    criterion1 = torch.nn.MSELoss()\n","\n","    for i, image in enumerate(input_tensor):\n","        grad_batch = image.unsqueeze(1).float()\n","\n","        grad_batch_noised, noise = gaussian_noise_gen(grad_batch, mode=\"train\")\n","        grad_batch_noised = grad_batch_noised.to(device)\n","        grad_batch_noised.requires_grad = True\n","        grad_batch_noised.retain_grad()\n","\n","        # forward pass\n","        grad_outputs = model(grad_batch_noised).float()\n","\n","        #forward pass + loss\n","        loss = criterion1(noise, grad_outputs)\n","\n","        #get saliency map\n","        grad = torch.autograd.grad(loss, grad_batch_noised)[0]\n","        grad, _ = torch.max(grad.relu(), 0)\n","        grad = grad.cpu().data.numpy()[0]\n","\n","        print(\"Saliency maps generated for iteration \", i)\n","\n","        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20, 10))\n","\n","        ax1.imshow(grad_batch.cpu().detach().numpy()[0][0], cmap = \"gray\")\n","        ax1.set_title(\"Original image\")\n","\n","\n","        sample_image_noised, _ = gaussian_noise_gen(grad_batch, mode=\"fixed\")\n","        sample_image_noised = sample_image_noised.cpu().detach().numpy()[0][0]\n","        ax2.imshow(sample_image_noised, cmap = \"gray\")\n","        ax2.set_title(\"Sample noisy image\")\n","\n","        ax3.imshow(grad_outputs.cpu().detach().numpy()[0][0], cmap = \"gray\")\n","        ax3.set_title(\"Denoised image\")\n","\n","        ax4.imshow(grad, cmap = \"hot\")\n","        ax4.set_title(\"Saliency map\")\n","\n","        plt.show()\n","        if i == 10:\n","            break\n","\n","    del grad_batch, grad_batch_noised, noise, grad_outputs, loss, grad, sample_image_noised, _, fig\n","    torch.cuda.empty_cache()\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if dec_train == 'y':\n","    \n","     #save the model\n","    dec_save = input('Do you want to save the model? (y/n)')\n","    if dec_save.lower() == 'y':\n","        dec_save2 = input(\"Please enter the index of the model you want to save.\")\n","        best_performing_model = models[int(dec_save2)]\n","        torch.save(best_performing_model, 'C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\denoisenet.pth')\n","        print('Model saved')\n","\n","    for i in statistics:\n","\n","        #grab statistics for each model\n","        print(\"Learning rate: \", i)\n","        print(\"Final PSNR: \", statistics[i][3][0])\n","        print(\"Final SSIM: \", statistics[i][3][1])\n","        print(\"Final RMSE: \", statistics[i][3][2])\n","\n","        #get training loss for every ith + 5th epoch\n","        training_loss_per_epoch = []\n","        for j in range(0, len(statistics[i][1]), 5):\n","            training_loss_per_epoch.append(statistics[i][1][j])\n","\n","        #plot the training and validation loss\n","        plt.plot(training_loss_per_epoch, label='training loss', color='blue')\n","        plt.plot(statistics[i][2], label='validation loss', color='orange', linestyle='dashed')\n","        plt.legend()\n","        plt.title('Training and Validation Loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss (log)')\n","        plt.yscale('log')\n","        plt.show()\n","\n","    #create saliency maps on the validation set\n","    torch.cuda.empty_cache()\n","    validation_partition = MRI_Dataset(data_path='C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\val_partition\\\\')\n","    val_dataloader = DataLoader(validation_partition, batch_size=1, shuffle=True, drop_last=True)\n","    try:\n","        saliency_generator(best_performing_model, val_dataloader)\n","    except:\n","        network = torch.load('C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\denoisenet.pth')\n","        print(\"Using pre-cached model from previous execution to generate saliency maps\")\n","        saliency_generator(network, val_dataloader)\n","        del network\n","\n","    #save statistics to a csv\n","    df = pd.DataFrame(statistics, index = ['model', 'training_loss', 'validation_loss', 'val_stats'])\n","    #check if a file exists\n","    if os.path.isfile('C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\statistics.csv'):\n","        df.to_csv('C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\statistics.csv', mode='a', header=True)\n","    else:\n","        df.to_csv('C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\statistics.csv')\n","    \n","    print(\"Statistics saved to csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test(model, data_path, anomaly_detection=False, device=device, partitions=0, d_type=\"synthetic\", sigma_gauss=5, dec_save=False):\n","  \"\"\"\n","  This function tests a model using the Mean Squared Error + SSIM loss function. Loss is computed to generate saliency maps from gradients. It also computes PSNR, SSIM, and RMSE metrics and compares the original image to the denoised image for visualization.\n","  It also compares network performance to a NLM denoising algorithm with smart gaussian sigma estimation. Can output the final denoised arrays for further analysis.\n","\n","  Parameters\n","  ----------\n","  model : torch.nn.Module\n","      The neural network model to be tested.\n","  data_path : str\n","      The path to the data to be used for testing.\n","  anomaly_detection : bool\n","      A flag to indicate whether to use PyTorch's anomaly detection feature. Also prints out diagnostic infomation across each step (verbose mode).\n","  device\n","      The device to be used for testing (e.g. 'cuda:0' or 'cpu').\n","  partitions : int\n","      The number of partitions to be used for testing.\n","  d_type : str\n","      The type of data to be used for testing (e.g. 'synthetic' or 'real').\n","  sigma_gauss : int\n","      The standard deviation of the Gaussian noise (in percent) to be added to the data.\n","  dec_save : bool\n","      A flag to indicate whether to save the denoised images as numpy arrays.\n","\n","  Returns\n","  -------\n","  test_loss_tracker : list\n","      A list of the test loss values.\n","  \n","  Examples\n","  --------\n","  >>> model = DenoiseNET().to(device)\n","  >>> test_loss_tracker = test(model, data_path='C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\normalized_pt_tensors\\\\test_partition\\\\', test_loss_tracker=[], anomaly_detection=False, device=device, partitions=5, d_type=\"synthetic\", sigma_gauss=5)\n","  \"\"\"\n","\n","  #initialize lists for metrics\n","  psnrs_init = []\n","  ssims_init = []\n","  rmses_init = []\n","  psnrs_final = []\n","  ssims_final = []\n","  rmses_final = []\n","\n","  psnrs_nlm = []\n","  ssims_nlm = []\n","  rmses_nlm = []\n","\n","  test_output_all = []\n","\n","  ssim_loss = StructuralSimilarityIndexMeasure(data_range=(-1.0, 1.0)).to(device)\n","  criterion1 = torch.nn.MSELoss()\n","\n","  ####start a timer####\n","  start = torch.cuda.Event(enable_timing=True)\n","  end = torch.cuda.Event(enable_timing=True)\n","  start.record()\n","\n","  model.eval()\n","  # prompt on whether save the denoised images\n","  if dec_save != False:\n","    dec_save = input('Do you want to save the denoised images as numpy arrays? (y/n)')\n","    dec_save = dec_save.lower()\n","    savedir = data_path + '\\\\denoised_imgs\\\\'\n","    os.makedirs(savedir, exist_ok=True)\n","\n","  for i in (range(partitions)): #change to whatever the length of the dataloader is - should be 5\n","    if anomaly_detection == True:\n","      print('loading in the test dataset of partition ', i)\n","    dataset_partition, test_dataloader = None, None\n","    torch.cuda.empty_cache()\n","\n","    #import the test dataset - don't shuffle or drop last to get all the images for saving, go through images one at a time\n","    dataset_partition = MRI_Dataset(data_path=(data_path + '\\\\partition_'+str(i)+'\\\\'), flip=False)\n","    test_dataloader = DataLoader(dataset_partition, batch_size=1, shuffle=False, drop_last=False) \n","        \n","    #training_loss_tracker.append(running_loss/counter)\n","    print('Testing partition:', i)\n","    for z, test_batch in tqdm.tqdm(enumerate(test_dataloader)):\n","      #fix any NaNs or Infs and add dimension for channel\n","      test_batch = test_batch.unsqueeze(1).float()\n","      test_batch = torch.nan_to_num(test_batch, nan=0.0, posinf=0.0, neginf=0.0)\n","\n","      #check that input has same dimensions as what teh model expects, and if not interpolate\n","      if test_batch.shape != (256, 256):\n","        test_batch = nn.functional.interpolate(test_batch, size = (256, 256), mode='bilinear', align_corners=True)\n","\n","      #gradient tracking\n","      test_batch.requires_grad = True\n","      test_batch.retain_grad()\n","\n","      #forward pass + loss\n","      if d_type == \"synthetic\":\n","        test_img, test_noise = gaussian_noise_gen(test_batch, mode=\"fixed\", fixed_sigma=sigma_gauss)\n","        test_img = test_img.float()\n","        test_noise = test_noise.float()\n","        test_outputs = model(test_img).float()\n","      elif d_type == \"real\":\n","        test_outputs = model(test_batch).float()\n","\n","      #recovered image for loss calculation\n","      recovered_img_test = test_batch - test_outputs\n","      if d_type == \"synthetic\":\n","        c1 = criterion1(test_noise, test_outputs)\n","        c3 = 1 - ssim_loss(test_batch, recovered_img_test)\n","        test_loss = 10*c1 + 0.1*c3\n","      elif d_type == \"real\":\n","        c3 = 1 - ssim_loss(test_batch, recovered_img_test)\n","        test_loss = 0.1*c3\n","    \n","      #send to cpu and convert to numpy for metrics\n","      test_batch_np = test_batch.cpu().data.numpy()\n","      if d_type == \"synthetic\":\n","        test_noised, _ = gaussian_noise_gen(test_batch, mode=\"fixed\", fixed_sigma=sigma_gauss)\n","        test_noised_np = test_noised.float().cpu().data.numpy()\n","      elif d_type == \"real\":\n","        test_noised = test_batch\n","        test_noised_np = test_noised.float().cpu().data.numpy()\n","      test_outputs_np = recovered_img_test.cpu().data.numpy()\n","\n","      #fix any NaNs or Infs\n","      test_batch_np = np.array(np.nan_to_num(test_batch_np, nan=0.0, posinf=0.0, neginf=0.0), copy=False, dtype=np.float32)\n","      test_noised_np = np.array(np.nan_to_num(test_noised_np, nan=0.0, posinf=0.0, neginf=0.0), copy=False, dtype=np.float32)\n","      test_outputs_np = np.array(np.nan_to_num(test_outputs_np, nan=0.0, posinf=0.0, neginf=0.0), copy=False, dtype=np.float32)\n","      \n","      #compute psnr, ssim and rmse for model\n","      initial_psnr = skimage.metrics.peak_signal_noise_ratio(test_batch_np, test_noised_np)\n","      psnrs_init.append(initial_psnr)\n","      final_psnr = skimage.metrics.peak_signal_noise_ratio(test_batch_np, test_outputs_np)\n","      psnrs_final.append(final_psnr)\n","      initial_ssim_comp = skimage.metrics.structural_similarity(((test_batch_np[0][0] * 1000).astype(np.uint16)), (test_noised_np[0][0]* 1000).astype(np.uint16), data_range=1000)\n","      ssims_init.append(initial_ssim_comp)\n","      final_ssim_comp = skimage.metrics.structural_similarity(((test_batch_np[0][0] * 1000).astype(np.uint16)), (test_outputs_np[0][0]* 1000).astype(np.uint16), data_range=1000)\n","      ssims_final.append(final_ssim_comp)\n","      initial_rmse = np.sqrt(skimage.metrics.mean_squared_error(test_batch_np, test_noised_np))\n","      rmses_init.append(initial_rmse)\n","      final_rmse = np.sqrt(skimage.metrics.mean_squared_error(test_batch_np, test_outputs_np))\n","      rmses_final.append(final_rmse)\n","\n","      #estimate sigma for NLM and denoise\n","      sigmas = []\n","      denoised_nlm = []\n","      for set in test_noised_np:\n","        for image in set:\n","          sigmas.append(np.mean(estimate_sigma(image, channel_axis=-1)))\n","      nlm_sigma = np.mean(sigmas)\n","      for set in test_noised_np:\n","        for image in set:\n","          denoised_nlm.append(denoise_nl_means(image, h=0.8 * nlm_sigma, fast_mode=True, patch_size=5, patch_distance=3, channel_axis=None))\n","      denoised_nlm = [denoised_nlm]\n","      denoised_nlm = np.array(denoised_nlm, copy=False, dtype=np.float32)\n","\n","      #compute psnr, ssim and rmse for NLM\n","      psnr_nlm = skimage.metrics.peak_signal_noise_ratio(test_batch_np, denoised_nlm)\n","      psnrs_nlm.append(psnr_nlm)\n","      ssim_nlm = skimage.metrics.structural_similarity(((test_batch_np[0][0] * 1000).astype(np.uint16)), (denoised_nlm[0][0]* 1000).astype(np.uint16), data_range=1000)\n","      ssims_nlm.append(ssim_nlm)\n","      rmse_nlm = np.sqrt(skimage.metrics.mean_squared_error(test_batch_np, denoised_nlm))\n","      rmses_nlm.append(rmse_nlm)\n","\n","      if dec_save == 'y':\n","        test_output_all.append(test_outputs_np)\n","\n","    #print statistics\n","    print('Initial PSNR: ', np.nanmean(psnrs_init))\n","    print('Final PSNR: ', np.nanmean(psnrs_final))\n","    print('Initial SSIM: ', np.nanmean(ssims_init))\n","    print('Final SSIM: ', np.nanmean(ssims_final))\n","    print('Initial RMSE: ', np.nanmean(rmses_init))\n","    print('Final RMSE: ', np.nanmean(rmses_final))\n","\n","    print('NLM PSNR: ', np.nanmean(psnrs_nlm))\n","    print('NLM SSIM: ', np.nanmean(ssims_nlm))\n","    print('NLM RMSE: ', np.nanmean(rmses_nlm))\n","\n","    #get saliency map\n","    grad = torch.autograd.grad(test_loss, test_batch)[0]\n","    grad, _ = torch.max(grad.relu(), 0) # take positive gradients only\n","    grad = grad.cpu().data.numpy()[0]\n","\n","    #create a sample image test for visualization\n","    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 10))\n","\n","    ax1.imshow(test_batch_np[0][0], cmap = \"gray\")\n","    ax1.set_title(\"Original image\")\n","\n","    ax2.imshow(test_noised_np[0][0], cmap = \"gray\")\n","    ax2.set_title(\"Sample noisy image\")\n","\n","    ax3.imshow(test_outputs_np[0][0], cmap = \"gray\")\n","    ax3.set_title(\"Denoised image\")\n","\n","    ax4.imshow(grad, cmap = \"hot\")\n","    ax4.set_title(\"Saliency map\")\n","\n","    ax5.imshow(denoised_nlm[0][0], cmap = \"gray\")\n","    ax5.set_title(\"Denoised image via NLM\")\n","\n","    plt.show()\n","\n","    # flush memory  \n","    del dataset_partition, test_dataloader, test_batch_np, test_noised_np, test_outputs_np, fig, ax1, ax2, ax3, ax4, ax5, grad, denoised_nlm, sigmas\n","    torch.cuda.empty_cache()\n","\n","  # whatever you are timing goes here\n","  end.record()\n","\n","  # Waits for everything to finish running\n","  torch.cuda.synchronize()\n","\n","  print('Finished Testing Session')\n","  print('Time elapsed in miliseconds: ', start.elapsed_time(end))  # milliseconds\n","\n","  # save statistics in export variables to be returned\n","  model_denoising_results = {\"psnr_init\": psnrs_init, \"ssim_init\": ssims_init, \"rmse_init\": rmses_init, \"psnr_final\": psnrs_final, \"ssim_final\": ssims_final, \"rmse_final\": rmses_final}\n","  nlm_denoising_results = {\"psnr_nlm\": psnrs_nlm, \"ssim_nlm\": ssims_nlm, \"rmse_nlm\": rmses_nlm}\n","\n","  # save the denoised images as numpy arrays for later use\n","  if dec_save == 'y':\n","    savedir = tkinter_gui(\"Please select the directory to save the denoised images\")\n","    saveloc = savedir + '\\\\' + \"denoised_imgs.npy\"\n","    np.save(saveloc, np.array(test_output_all))\n","\n","  return model_denoising_results, nlm_denoising_results\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dec2 = input(\"Do you want to test the model? (y/n): \")\n","if dec2.lower() == 'y':\n","    #load in latest saved model\n","    torch.cuda.empty_cache()\n","    network = torch.load('C:\\\\Users\\\\miker\\\\Downloads\\\\IXI-T1\\\\denoisenet.pth')\n","    network.to(device)\n","\n","    #select the partitioned data folder\n","    partition_folder_path = tkinter_gui(\"Select the folder containing the partitioned data\")\n","    denoise_stats_container = {}\n","    nlm_stats_container = {}\n","\n","    if \"IXI\" in partition_folder_path.upper() or \"NYU\" in partition_folder_path.upper():\n","        sigmas = [1,3,5,7,9]\n","\n","        # test for each pre-defined gaussian sigma\n","        for sigma in sigmas:\n","            data_type = 's'\n","            print(\"Testing for sigma: \", sigma)\n","            model_denoise_perf, nlm_denoise_perf = test(network, partition_folder_path, anomaly_detection=False, device=device, partitions=1, d_type='synthetic', sigma_gauss=sigma)\n","            denoise_stats_container[sigma] = model_denoise_perf\n","            nlm_stats_container[sigma] = nlm_denoise_perf\n","\n","    else:\n","        data_type = input(\"Enter the data type (e.g. s for synthetic data with noise-generation required, or r for real low-field data): \")\n","        #test at one pre-defined sigma\n","        if data_type.lower() == 's':\n","            model_denoise_perf, nlm_denoise_perf = test(network, partition_folder_path, anomaly_detection=False, device=device, partitions=1, d_type='synthetic', sigma_gauss=9)\n","            denoise_stats_container[9] = model_denoise_perf\n","            nlm_stats_container[9] = nlm_denoise_perf\n","        #test with real data\n","        elif data_type.lower() == 'r':\n","            model_denoise_perf, nlm_denoise_perf = test(network, partition_folder_path, anomaly_detection=False, device=device, partitions=1, d_type='real', dec_save=True)\n","            denoise_stats_container[0] = model_denoise_perf\n","            nlm_stats_container[0] = nlm_denoise_perf\n","\n","    test_values = {}\n","\n","#print statistics for each sigma to allow evaluation of test performance\n","for sigma in denoise_stats_container:\n","    print(\"Sigma: \", sigma)\n","    init_psnr_mean = np.nanmean(denoise_stats_container[sigma]['psnr_init'])\n","    init_psnr_std = np.nanstd(denoise_stats_container[sigma]['psnr_init'])\n","    print(\"Initial PSNR: \", round(init_psnr_mean,5), \"+-\", round(init_psnr_std,5))\n","    init_ssim_mean = np.nanmean(denoise_stats_container[sigma]['ssim_init'])\n","    init_ssim_std = np.nanstd(denoise_stats_container[sigma]['ssim_init'])\n","    print(\"Initial SSIM: \", round(init_ssim_mean,5), \"+-\", round(init_ssim_std,5))\n","    init_rmse_mean = np.nanmean(denoise_stats_container[sigma]['rmse_init'])\n","    init_rmse_std = np.nanstd(denoise_stats_container[sigma]['rmse_init'])\n","    print(\"Initial RMSE: \", round(init_rmse_mean,5), \"+-\", round(init_rmse_std,5))\n","    final_psnr_mean = np.nanmean(denoise_stats_container[sigma]['psnr_final'])\n","    final_psnr_std = np.nanstd(denoise_stats_container[sigma]['psnr_final'])\n","    print(\"Final PSNR: \", round(final_psnr_mean,5), \"+-\", round(final_psnr_std,5))\n","    final_ssim_mean = np.nanmean(denoise_stats_container[sigma]['ssim_final'])\n","    final_ssim_std = np.nanstd(denoise_stats_container[sigma]['ssim_final'])\n","    print(\"Final SSIM: \", round(final_ssim_mean,5), \"+-\", round(final_ssim_std,5))\n","    final_rmse_mean = np.nanmean(denoise_stats_container[sigma]['rmse_final'])\n","    final_rmse_std = np.nanstd(denoise_stats_container[sigma]['rmse_final'])\n","    print(\"Final RMSE: \", round(final_rmse_mean,5), \"+-\", round(final_rmse_std,5))\n","    print(\"p-value PSNR: \", ttest_rel(denoise_stats_container[sigma]['psnr_init'], denoise_stats_container[sigma]['psnr_final'])[1])\n","    print(\"p-value RMSE: \", ttest_rel(denoise_stats_container[sigma]['rmse_init'], denoise_stats_container[sigma]['rmse_final'])[1])\n","    nlm_psnr_mean = np.nanmean(nlm_stats_container[sigma]['psnr_nlm'])\n","    nlm_psnr_std = np.nanstd(nlm_stats_container[sigma]['psnr_nlm'])\n","    print(\"NLM PSNR: \", round(nlm_psnr_mean,5), \"+-\", round(nlm_psnr_std,5))\n","    nlm_ssim_mean = np.nanmean(nlm_stats_container[sigma]['ssim_nlm'])\n","    nlm_ssim_std = np.nanstd(nlm_stats_container[sigma]['ssim_nlm'])\n","    print(\"NLM SSIM: \", round(nlm_ssim_mean,5), \"+-\", round(nlm_ssim_std,5))\n","    nlm_rmse_mean = np.nanmean(nlm_stats_container[sigma]['rmse_nlm'])\n","    nlm_rmse_std = np.nanstd(nlm_stats_container[sigma]['rmse_nlm'])\n","    print(\"NLM RMSE: \", round(nlm_rmse_mean,5), \"+-\", round(nlm_rmse_std,5))\n","    print(\"\\n\")\n","    test_values[sigma] = {\"init_psnr_mean\": init_psnr_mean, \"init_psnr_std\": init_psnr_std, \"init_ssim_mean\": init_ssim_mean, \"init_ssim_std\": init_ssim_std, \"init_rmse_mean\": init_rmse_mean, \"init_rmse_std\": init_rmse_std, \"final_psnr_mean\": final_psnr_mean, \n","                          \"final_psnr_std\": final_psnr_std, \"final_ssim_mean\": final_ssim_mean, \"final_ssim_std\": final_ssim_std, \"final_rmse_mean\": final_rmse_mean, \"final_rmse_std\": final_rmse_std, \"p-value_psnr\": ttest_rel(denoise_stats_container[sigma]['psnr_init'], \n","                           denoise_stats_container[sigma]['psnr_final'])[1], \"p-value_rmse\": ttest_rel(denoise_stats_container[sigma]['rmse_init'], denoise_stats_container[sigma]['rmse_final'])[1], \"nlm_psnr_mean\": nlm_psnr_mean, \"nlm_psnr_std\": nlm_psnr_std, \n","                           \"nlm_ssim_mean\": nlm_ssim_mean, \"nlm_ssim_std\": nlm_ssim_std, \"nlm_rmse_mean\": nlm_rmse_mean, \"nlm_rmse_std\": nlm_rmse_std}\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["rV4a9SKm8pTR","IF7D5n1w6Op5","f8h4FKmECmOY"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
